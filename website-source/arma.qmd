---
title: "ARMA/ARIMA/SARIMA Models"
---

In this section, we will delve into the application of ARMA, ARIMA, and SARIMA models to better understand the time series of greenhouse gas concentrations. We will continue to focus on variables such as carbon dioxide, methane, nitrous oxide, and sulfur hexafluoride, provided by the Global Monitoring Laboratory at NOAA. These time series are interconnected, as many greenhouse gas emitters release multiple gases, and all are generally associated with increased industrialization. To effectively analyze the relationships and trends in these time series, we will employ these models to capture temporal dependencies and seasonal patterns.

## Background

ARMA (Autoregressive Moving Average) and ARIMA (Autoregressive Integrated Moving Average) are widely used forecasting algorithms in time series data analysis, enabling the prediction of changes in a single variable over time while considering its past values and associated error terms. The ARMA model comprises the autoregressive (AR) part, representing the dependency on previous values, and the moving average (MA) part, accounting for the dependency on previous error terms. The ARIMA model extends the ARMA framework by incorporating the Integrated (I) component, which involves differencing the data to achieve stationarity, making it suitable for handling non-stationary time series data.

The Seasonal ARIMA (SARIMA) model further expands the capabilities of the ARIMA model by addressing seasonality in the data. It includes additional seasonal autoregressive, differencing, and moving average components, enabling it to capture both regular and seasonal patterns in the time series. Despite some limitations, such as the assumption of constant relationships over time and potential difficulties in capturing complex non-linear relationships, ARMA, ARIMA, and SARIMA models remain essential tools in univariate time series analysis. They offer a solid foundation for understanding the behavior of greenhouse gas concentrations over time, providing valuable insights into the evolving state of our environment.

## ARIMA: SF6 Concentration

```{r ,echo=FALSE, message=FALSE, warning=FALSE}
library(flipbookr)
library(tidyverse)
library(ggplot2)
library(forecast)
library(astsa) 
library(xts)
library(tseries)
library(fpp2)
library(fma)
library(lubridate)
library(tidyverse)
library(TSstudio)
library(quantmod)
library(tidyquant)
library(plotly)
library(ggplot2)
library(vars)
```

For this section, we will be using an ARIMA model to forecast future atmospheric concentrations of sulfur hexaflouride.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
sf6 = read.csv('sf6.csv')

sf6 = read.csv('sf6.csv')
g = ggplot(sf6, aes(x=decimal, y=average)) +
  geom_line(color='darkgreen', size=1) +
  theme_minimal() + 
  labs(title='Mean Monthly Sulfur Hexafluoride Concentration since 1997',x='Year',y='Sulfur Hexafluoride (ppt)')
ggplotly(g)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#converting the data into a time series object 
SF6_Concentration <- ts(sf6$average, start=c(1997,7), frequency=12)
```

#### SF6 Concentration (No differencing)

```{r, echo=FALSE, message=FALSE, warning=FALSE}
SF6_Concentration %>% ggtsdisplay()
```

The above plots show the ACF and PACF for the Sulfur Hexafluoride concentration time series. As expected, the ACF plot shows a very high degree of correlation between values, indicating that this series is not stationary. This follows the previous hypothesis that the series was not stationary due to the strong trend and weak seasonality. Since the series is not stationary, there are several options available to make it so. One of these options is differencing, where the values are recaluclated by subtracting each from the previous, providing the difference between each pair of values. Other methods include smoothing the data with a moving average or using a Box-Cox transformation to bring the data into a more stationary state. Ultimately, the goal of these transformations is to make the data stationary so that it can be better modeled and better predictions can be made.

#### SF6 Concentration (1st order difference)

```{r, echo=FALSE, message=FALSE, warning=FALSE}

SF6_Concentration %>% diff() %>% ggtsdisplay()
```

These plots demonstrate the first-order differencing of the time series. After eliminating most of the trend component, the seasonality is much more visible in the ACF plot. It is also worth noting that the magnitude of the bars in the differenced graph is much smaller than that of the initial ACF plot. A closer analysis of the ACF plot reveals that the seasonality remains relatively strong even after one differencing.The seasonal spikes appear every 12, 24 and 36 months, which is the expected result for a monthly series. Even though there is still an obvious pattern in the ACF plot, it is necessary to differentiate the series once again to make it stationary.

#### SF6 Concentration (2nd order difference)

```{r, echo=FALSE, message=FALSE, warning=FALSE}

SF6_Concentration %>% diff() %>% diff() %>% ggtsdisplay()
```

After taking the difference for the second time, the plots are showing much stronger indications that the series is now stationary. Through it is not perfect, the ACF plot has much less correlation across the range of lag parameters. Although there are still some spikes at 12 and 24 months, taking another difference would not be unreasonable. However, it is important to note that if we over difference the data, it will be much more difficult to detect the signal that we are aiming for. This is evident when we look at the 3rd order difference, where the plot is almost indistinguishable from white noise. As a result, it is critical to be mindful of the order of difference when analyzing time series data.

The Augmented Dickey-Fuller Test (ADF) is a powerful tool for testing for stationarity in a time series. To ensure a comprehensive analysis, the ADF test should be run on the undifferenced, 1st order, and 2nd order difference of the time series. By doing so, we can compare the results and gain a clearer understanding of stationarity. The results of the ADF test are displayed below.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
print(adf.test(SF6_Concentration))
print(adf.test(SF6_Concentration %>% diff() ))
print(adf.test(SF6_Concentration %>% diff() %>% diff() ))
```

The results of the ADF test indicate that both the 1st and 2nd order differences are stationary, while the undifferenced series is not. This matches my hypothesis, with the exception of the first order difference. Inspection of this ACF plot reveals a clear pattern of correlation at 12 and 24 months. I find it quite puzzling that the ADF test believes that this series is stationary despite the spikes in the ACF plot.

#### Parameter Selection

Based on the PACF and ACF plots, I will be modeling the twice-differenced $SF_6$ concentration because I want to ensure that our series is stationary. Based on the ACF and PACF plots of the twice differenced $SF_6$ concentration shown above, I will select 1 and 3 as possible choices for $p$ and 1,2,3, and 4 as possible choices for $q$. Since this data is twice differenced, I will be using a $q$ value of 2.

After running the model, we get the following table of AIC and BIC values based on the model parameters.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
i=1
ls=matrix(rep(NA,6*8),nrow=8)

for (p in c(1,3)){
  for(q in 1:4){
    model<- Arima(SF6_Concentration,order=c(p-1,2,q-1)) 
    ls[i,]= c(p-1,2,q-1,model$aic,model$bic,model$aicc)
    i=i+1
  }
}
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
temp = data.frame()
temp = as.data.frame(ls)
names(temp)= c("p","d","q","AIC","BIC","AICc")
knitr::kable(temp)
```

Based on the table, the model with the lowest AIC and BIC scores is the 2,2,2 model. None of the other models are that close to this one in terms of AIC and BIC scores. For the sake of comparison, I will select the worst model of the bunch (0,2,0) to show that even this is very similar to our best model. All of the option here would be adequate for forecasting this series.

#### Model Diagnostics

For a (2,2,2) ARIMA model, the equation is:

$$y(t) = c + ϕ(1)*y(t-1) + ϕ(2)*y(t-2) - θ(1)*ε(t-1) - θ(2)*ε(t-2) + ε(t)$$

where:

-   $y(t)$ is the value of the time series at time t
-   $c$ is a constant term (i.e., the mean of the series)
-   $ϕ(1)$ and $ϕ(2)$ are the autoregressive coefficients for lags 1 and 2, respectively
-   $θ(1)$ and $θ(2)$ are the moving average coefficients for lags 1 and 2, respectively
-   $ε(t)$ is white noise (i.e., a random error term) with mean zero and constant variance

Now, lets consider the model diagnostics using standardized residuals.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
model_output <- capture.output(sarima(SF6_Concentration, 2,2,2))
```

For the most part, the residuals plots looks as we would expect. The residuals have a constant mean and variance, and the lagged p-values for the Ljung-Box statistic are under the 0.05 threshold for all except two of the lags. Something that does still appear is a spike in ACF residuals at lags 12 and 24. This would suggest that the series may not have been adequately stationary prior ro modeling. However, we mentioned this earlier, and it wsa determined that twice-differenced was the proper metric to use, as three-times differences would over difference the data and lose valuable insights.

Next, we can plot the raw data, our chosen model (2,2,2), and the second model (0,2,0) on the same plot to see how they compare on the training data. As expected, both models are nearly identical to the SF6 data. The lines are directly on top of each other and it is impossible to make out any difference between the models and the data.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
fit1=Arima(SF6_Concentration,order=c(2,2,2))
fit2=Arima(SF6_Concentration,order=c(0,2,0))

plot(SF6_Concentration, col="blue")
lines(fitted(fit1),col="green")
lines(fitted(fit2),col="red")
legend(x = "topleft", legend = c("SF6", "fit1", "fit2"), fill = 4:1)
```

#### Auto-arima

Next, we can compare our ARIMA(2,2,2) model to the auto-arima model. Thankfully, the auto-arima function provides the same model as the one we came to through traditional means. This is validating because there were many choices for p,d, and q, so it is nice to know that the best model was selected in both methods.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
auto.arima(SF6_Concentration, seasonal = FALSE)
```

#### 10-year Forecast

Finally, we can use the ARIMA model to forecast the SF6 concentration over the next 10 years (120 months). The plot below shows the forecast of the ARIMA(2,2,2) model.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
autoplot(forecast(fit1,120))
```

#### Benchmark Methods

In order to determine the effectiveness of our model, we need to compare to other benchmark methods. Based on the graphs and accuracy tests below, it is clear that the ARIMA(2,2,2) model far outperforms any of the benchmark methods. Thus, we can be confident when using this model going forward.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
autoplot(SF6_Concentration) +
  autolayer(meanf(SF6_Concentration, h=120),
            series="Mean", PI=FALSE) +
  autolayer(meanf(SF6_Concentration, h=120),
            series="Mean.tr", PI=FALSE) +
  autolayer(naive(SF6_Concentration, h=120),
            series="Naïve", PI=FALSE) +
  autolayer(naive(SF6_Concentration, h=120),
            series="Naïve.tr", PI=FALSE) +
  autolayer(rwf(SF6_Concentration, drift=TRUE, h=120),
            series="Drift", PI=FALSE) +
  autolayer(forecast(fit1,120), 
            series="fit",PI=FALSE) +
  ggtitle(" Sulfur Hexafluoride Concentration since 1997") +
  xlab("Year") + ylab("Concentration") +
  guides(colour=guide_legend(title="Forecast"))
```

```{r}
pred1=forecast(fit1, h=120);
accuracy(pred1)
```

```{r}
f1 <- meanf(SF6_Concentration, h=120)
accuracy(f1)
```

```{r}
f2 <- naive(SF6_Concentration, h=120)
accuracy(f2)
```

```{r}
f3 <- rwf(SF6_Concentration, h=120)
accuracy(f3)
```

## SARIMA: CO2 Concentration

In this section, we will use a Seasonal Autoregressive Integrated Moving Average (SARIMA) model to forecast future atmospheric concentrations of carbon dioxide. As the graph below illustrates, the CO2 concentration, though representing a global mean, exhibits a strong seasonal pattern. Therefore, we will employ a SARIMA model for our analysis.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
co2 = read.csv('co2.csv')

g = ggplot(co2, aes(x=decimal, y=average)) +
  geom_line(color='darkgreen', size=1) +
  theme_minimal() + 
  labs(title='Mean Monthly Carbon Dioxide Concentration since 1997',x='Year',y='Carbon Dioxide (ppm)')
ggplotly(g)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#converting the data into a time series object 
CO2_Concentration <- ts(co2$average, start=c(1958,3), frequency=12)
```

#### CO2 Concentration (No differencing)

```{r, echo=FALSE, message=FALSE, warning=FALSE}
CO2_Concentration %>% ggtsdisplay()
```

The above plots display the Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) for the CO2 concentration time series. As anticipated, the ACF plot reveals a strong correlation between values, signifying that this series is non-stationary. This aligns with our previous assumption that the series is non-stationary due to its pronounced seasonality. To achieve stationarity, we will apply differencing.

```{r}
autoplot(decompose(CO2_Concentration))
```

#### Monthly Lags

Before performing differencing, we examine the monthly lag plots to determine the length of the seasonality. Based on domain knowledge, we suspect a 12-month lag, as the seasonal pattern recurs annually. The lag plots below confirm this hypothesis. The Month 12 lag plots exhibit an almost perfect y=x line, which is superior to all other lags up to 12 months.

```{r}
gglagplot(CO2_Concentration, do.lines=FALSE, lags=12)+xlab("Xi")+ylab("Yi")+ggtitle("Lag Plot for Monthly CO2_Concentration (1958-2023)")

```

#### Twice Differences (Once Seasonal and Once Standard)

Having identified the seasonal lag, we can now use differencing to make the series stationary. We apply one seasonal differencing and one standard differencing to achieve stationarity. The resulting ACF and PACF plots exhibit no seasonal pattern or serial autocorrelation, indicating that our data is now differenced and ready for parameter selection and model creation.

```{r}
CO2_Concentration %>% diff(lag=12) %>% diff() %>% ggtsdisplay()
```

#### Parameter Selection

Using the ACF and PACF plots of the differenced data, we can identify potential values for the parameters p, P, q, and Q. Note that d and D have already been determined based on the differencing performed in the previous step. The ACF and PACF plots suggest the following possible values for each parameter:

-   q = 0,1

-   Q = 0,1

-   p = 0,1,2,3

-   P = 0,1,2,3

-   d = 1

-   D = 1

After running the model, we get the following table of AIC and BIC values based on the model parameters.

```{r}
#write a funtion
SARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,data){
  
  temp=c()
  d=1
  D=1
  s=12
  
  i=1
  temp= data.frame()
  ls=matrix(rep(NA,9*25),nrow=25)
  
  for (p in p1:p2){
    for(q in q1:q2){
      for(P in P1:P2){
        for(Q in Q1:Q2){
          if(p+d+q+P+D+Q<=9){
            model<- Arima(data,order=c(p-1,d,q-1),seasonal=c(P-1,D,Q-1))
            ls[i,]= c(p-1,d,q-1,P-1,D,Q-1,model$aic,model$bic,model$aicc)
            i=i+1
          }
        }
      }
    }
  }
  temp= as.data.frame(ls)
  names(temp)= c("p","d","q","P","D","Q","AIC","BIC","AICc")
  temp
}

output=SARIMA.c(p1=1,p2=4,q1=1,q2=2,P1=1,P2=4,Q1=1,Q2=2,data=CO2_Concentration)
knitr::kable(output)
```

According to the AIC and BIC scores, the best model is the (1,1,1)(0,1,1) model, as it has the lowest AIC and BIC scores. Several other models also have similar AIC and BIC scores, but upon comparing the top models, the (1,1,1)(0,1,1) model is indeed the best one. However, all the options here would provide adequate forecasts for this series, as their performance is very similar.

#### Model Diagnostics

Now, let's examine the model diagnostics using standardized residuals.

```{r}
model_output <- capture.output(sarima(CO2_Concentration,1,1,1,0,1,1,12))
```

```{r}
fit1 <- Arima(CO2_Concentration, order=c(1,1,1), seasonal=c(0,1,1))
summary(fit1)
```

#### Cross-Validation

To further validate our SARIMA(1,1,1)(0,1,1) model, we will perform a one-step-ahead cross-validation. In this approach, we iteratively train the model on a portion of the data and then use the model to forecast the next point. We compare this forecast to the actual data and calculate the error. This process is repeated for each data point in the time series, and the overall accuracy of the model is assessed using the mean squared error (MSE) of the one-step-ahead forecasts.

```{r}
# Cross-validation function
one_step_ahead_cv <- function(data, order, seasonal_order) {
  n <- length(data)
  errors <- numeric(n)
  
  for (t in (length(seasonal_order) + 2):n) {
    train_data <- window(data, end = t - 1)
    test_data <- data[t]
    if (length(train_data) > 0) {
      model <- Arima(train_data, order = order, seasonal = seasonal_order)
      forecasted_value <- forecast(model, h = 1)$mean
      errors[t] <- (forecasted_value - test_data)^2
    }
  }
  
  mean(errors, na.rm = TRUE)
}
```

```{r}
# Perform cross-validation
# mse <- one_step_ahead_cv(data = CO2_Concentration, order = c(1, 1, 1), seasonal_order = c(0, 1, 1))
# mse
```

#### Benchmark Methods and Forecast

To evaluate the effectiveness of our model, we will compare it to other benchmark methods. The graphs and accuracy tests below demonstrate that the SARIMA(1,1,1)(0,1,1) model significantly outperforms any of the benchmark methods. This gives us confidence in using this model for our forecasts.

```{r}
autoplot(CO2_Concentration) +
  autolayer(meanf(CO2_Concentration, h=120),
            series="Mean", PI=FALSE) +
  autolayer(naive(CO2_Concentration, h=120),
            series="Naïve", PI=FALSE) +
  autolayer(snaive(CO2_Concentration, h=120),
            series="SNaïve", PI=FALSE)+
  autolayer(rwf(CO2_Concentration, h=120, drift=TRUE),
            series="Drift", PI=FALSE)+
  autolayer(forecast(fit1,120), 
            series="fit",PI=FALSE) +
  guides(colour=guide_legend(title="Forecast"))
```

Finally, we can use the SARIMA model to forecast the CO2 concentration over the next 10 years (120 months). The plot below shows the forecast of the ARIMA(1,1,1)(0,1,1) model.

```{r}
fit1 %>% forecast(h=120) %>% autoplot()
```

In conclusion, we have successfully built and validated a SARIMA(1,1,1)(0,1,1) model for forecasting future atmospheric concentrations of carbon dioxide. This model effectively accounts for the seasonality present in the CO2 concentration data and outperforms the benchmark methods. Utilizing this model, we can now generate forecasts of CO2 concentrations over the next 10 years and contribute to the understanding of potential future trends in atmospheric CO2 levels.
